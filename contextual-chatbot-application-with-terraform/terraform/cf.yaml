AWSTemplateFormatVersion: "2010-09-09"
Description: A template for Knowledge base with Amazon Opensearch Serverless vector database.
Parameters:
  KnowledgeBaseName:
    Default: bedrock-knowledgebase
    Type: String
    Description: The name of the knowledge base.
  KnowledgeBaseDescription:
    Type: String
    Description: The description of the knowledge base.
    Default: Amazon Bedrock Knowledge Base.
  DataSourceName:
    Default: bedrock-knowledgebase-datasource
    Type: String
    Description: The name of the data source.
  DataSourceDescription:
    Type: String
    Description: The description of the data source.
    Default: Amazon Bedrock Knowledge Base data source.
  S3BucketName:
    Type: String
    Description: The S3 bucket stores that dataset and lambda layer code
  AOSSCollectionName:
    Default: bedrock-kb-aoss
    Type: String
    Description: Amazon OpenSearch Service Serverless (AOSS) collection for Amazon Bedrock Knowledge Base.


Resources:
  AmazonBedrockExecutionRoleForKnowledgeBase:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Join
      - '-'
      - - AmazonBedrockExecutionRoleForKnowledgeBase
        - !Ref AOSSCollectionName
      AssumeRolePolicyDocument:
        Statement:
        - Effect: Allow
          Principal:
            Service: bedrock.amazonaws.com
          Action: sts:AssumeRole
          Condition:
            StringEquals:
              "aws:SourceAccount": !Sub "${AWS::AccountId}"
            ArnLike:
              "AWS:SourceArn": !Sub "arn:aws:bedrock:${AWS::Region}:${AWS::AccountId}:knowledge-base/*"
      Path: /
      Policies:
        - PolicyName: S3ReadOnlyAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:Get*
                  - s3:List*
                  - s3:Describe*
                  - s3-object-lambda:Get*,
                  - s3-object-lambda:List*
                Resource: '*'
        - PolicyName: AOSSAPIAccessAll
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - aoss:APIAccessAll
                Resource: !Sub arn:aws:aoss:${AWS::Region}:${AWS::AccountId}:collection/*
        - PolicyName: BedrockListAndInvokeModel
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:ListCustomModels
                Resource: '*'
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                Resource: !Sub arn:aws:bedrock:${AWS::Region}::foundation-model/*
  
  CreateVectorIndexLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Effect: Allow
          Principal:
            Service: lambda.amazonaws.com
          Action: sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: AOSS-Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: arn:aws:logs:*:*:*
              - Effect: Allow
                Action:
                  - aoss:CreateCollection
                  - aoss:DeleteCollection
                  - aoss:CreateAccessPolicy
                  - aoss:CreateSecurityPolicy
                  - aoss:BatchGetCollection
                  - aoss:ListCollections
                  - aoss:UpdateCollection
                  - aoss:APIAccessAll 
                Resource: '*'
  
  CreateVectorIndexLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Description: !Sub "Create Vector Index in ${AOSSCollectionName} Collection"
      Timeout: 120
      Role: !GetAtt 'CreateVectorIndexLambdaRole.Arn'
      Runtime: python3.12
      Layers: 
        - !Ref CreateAOSSIndexLambdaLayer
      Environment:
        Variables:
          AOSS_COLLECTION_NAME: !Ref AOSSCollectionName
      Code:
        ZipFile: |
          import os
          from opensearchpy import OpenSearch, RequestsHttpConnection
          from requests_aws4auth import AWS4Auth
          import boto3
          import botocore
          import time
          import cfnresponse
          import logging
          from botocore.exceptions import ClientError

          def lambda_handler(event, context):
            logger = logging.getLogger()
            logger.setLevel(logging.INFO)
            logger.info('got event {}'.format(event))
            # Build the client using the default credential configuration.
            # You can use the CLI and run 'aws configure' to set access key, secret
            # key, and default region.
            index_name="bedrock-knowledge-base-default-index"
            client = boto3.client('opensearchserverless')
            service = 'aoss'
            region = os.environ['AWS_REGION']
            credentials = boto3.Session().get_credentials()
            awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,
                              region, service, session_token=credentials.token)
            
            response = client.batch_get_collection(
                names=[f"{os.environ.get('AOSS_COLLECTION_NAME')}"])
            # Periodically check collection status
            while (response['collectionDetails'][0]['status']) == 'CREATING':
                print('Fetching collection...')
                time.sleep(30)
                response = client.batch_get_collection(
                    names=[f"{os.environ.get('AOSS_COLLECTION_NAME')}"])
            print('\nCollection successfully fetched:')
            print(response["collectionDetails"])
            # Extract the collection endpoint from the response
            host = (response['collectionDetails'][0]['collectionEndpoint'])
            final_host = host.replace("https://", "")

            """Create an index"""
            # Build the OpenSearch client
            try:
                client = OpenSearch(
                    hosts=[{'host': final_host, 'port': 443}],
                    http_auth=awsauth,
                    use_ssl=True,
                    verify_certs=True,
                    connection_class=RequestsHttpConnection,
                    timeout=300
                )
                if event['RequestType'] == 'Create':
                    # Create index if not exist
                    if not client.indices.exists(index=index_name):
                        response = client.indices.create(
                            index=index_name,
                            body={
                                "settings": {
                                  "index.knn": True
                                },
                                "mappings": {
                                    "properties": {
                                        "bedrock-knowledge-base-default-vector": {
                                          "type": "knn_vector",
                                          "dimension": 1536,
                                          "method": {
                                            "engine": "faiss",
                                            "name": "hnsw"
                                          }
                                        },
                                        "AMAZON_BEDROCK_TEXT_CHUNK": {
                                            "type": "text",
                                        },
                                        "AMAZON_BEDROCK_METADATA": {
                                            "type": "text",
                                            "index": False
                                        }
                                    }
                                }
                            }
                        )
                        print('\nCreating index:')
                        time.sleep(30)
                        print(response)
                        cfnresponse.send(event, context, cfnresponse.SUCCESS, response)
                    else:
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, 'Index Already Exists')
                    
                if event['RequestType'] == 'Delete':
                  response = client.indices.delete(
                            index=index_name,
                            )
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, response)
            
            except Exception as e:
                logger.error(e)
                response = dict(files_copied=0, error=str(e))
                cfnresponse.send(event, context, cfnresponse.FAILED, response)

            return

    DependsOn: 
    - Collection
    - NetworkPolicy
    - EncryptionPolicy
    - DataAccessPolicy
  
  CustomSGResource:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt 'CreateVectorIndexLambdaFunction.Arn'
    DependsOn: 
    - Collection
    - NetworkPolicy
    - EncryptionPolicy
    - DataAccessPolicy
  
  DataAccessPolicy:
    Type: 'AWS::OpenSearchServerless::AccessPolicy'
    Properties:
      Name: !Join
      - '-'
      - - !Ref AOSSCollectionName
        - access-policy
      Type: data
      Description: Access policy for AOSS collection
      Policy: !Sub >-
        [{"Description":"Access for cfn user","Rules":[{"ResourceType":"index","Resource":["index/*/*"],"Permission":["aoss:*"]},
        {"ResourceType":"collection","Resource":["collection/${AOSSCollectionName}"],"Permission":["aoss:*"]}],
        "Principal":["${AmazonBedrockExecutionRoleForKnowledgeBase.Arn}","${CreateVectorIndexLambdaRole.Arn}"]}]
  
  NetworkPolicy:
    Type: 'AWS::OpenSearchServerless::SecurityPolicy'
    Properties:
      Name: !Join
      - '-'
      - - !Ref AOSSCollectionName
        - network-policy
      Type: network
      Description: Network policy for AOSS collection
      Policy: !Sub >-
        [{"Rules":[{"ResourceType":"collection","Resource":["collection/${AOSSCollectionName}"]}, {"ResourceType":"dashboard","Resource":["collection/${AOSSCollectionName}"]}],"AllowFromPublic":true}]
  
  EncryptionPolicy:
    Type: 'AWS::OpenSearchServerless::SecurityPolicy'
    Properties:
      Name: !Join
      - '-'
      - - !Ref AOSSCollectionName
        - security-policy
      Type: encryption
      Description: Encryption policy for AOSS collection
      Policy: !Sub >-
        {"Rules":[{"ResourceType":"collection","Resource":["collection/${AOSSCollectionName}"]}],"AWSOwnedKey":true}
  
  Collection:
    Type: 'AWS::OpenSearchServerless::Collection'
    Properties:
      Name: !Ref AOSSCollectionName
      Type: VECTORSEARCH
      Description: Bedrock Knowledgebase Collection
    DependsOn: EncryptionPolicy
  
  KnowledgeBaseWithAoss:
    Type: AWS::Bedrock::KnowledgeBase
    Properties:
      Name: !Ref KnowledgeBaseName
      Description: !Ref KnowledgeBaseDescription
      RoleArn: !GetAtt 'AmazonBedrockExecutionRoleForKnowledgeBase.Arn'
      KnowledgeBaseConfiguration:
        Type: "VECTOR"
        VectorKnowledgeBaseConfiguration:
          EmbeddingModelArn: !Sub "arn:${AWS::Partition}:bedrock:${AWS::Region}::foundation-model/amazon.titan-embed-text-v1"
      StorageConfiguration:
        Type: "OPENSEARCH_SERVERLESS"
        OpensearchServerlessConfiguration:
          CollectionArn: !GetAtt 'Collection.Arn'
          VectorIndexName: "bedrock-knowledge-base-default-index"
          FieldMapping:
            VectorField: "bedrock-knowledge-base-default-vector"
            TextField: "AMAZON_BEDROCK_TEXT_CHUNK"
            MetadataField: "AMAZON_BEDROCK_METADATA"
    DependsOn: 
    - CreateVectorIndexLambdaFunction
    - CustomSGResource
  
  DataSource:
    Type: AWS::Bedrock::DataSource
    Properties:
      KnowledgeBaseId: !Ref KnowledgeBaseWithAoss
      Name: !Ref DataSourceName
      Description: !Ref DataSourceDescription
      DataSourceConfiguration:
        Type: "S3"
        S3Configuration:
          BucketArn: !Sub "arn:aws:s3:::${S3BucketName}"
  
  LambdaExecutionRoleForKnowledgeBase:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - "sts:AssumeRole"
      Path: /
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
      Policies:
        - PolicyName: KnowledgeBaseExecutionPermissions
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'bedrock:InvokeModel'
                  - 'bedrock:Retrieve'
                  - 'bedrock:RetrieveAndGenerate'
                Resource: '*'

  CreateAOSSIndexLambdaLayer:
    Type: Custom::AOSSIndexLambdaLayer
    Properties:
      ServiceToken: !GetAtt PipLayerLambda.Arn
      Region: !Ref AWS::Region
      LayerName: AOSSIndexLambdaLayer
      Packages:
        - opensearch-py
        - requests-aws4auth

  PipLayerLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
      Policies:
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                - logs:CreateLogGroup
                - logs:CreateLogStream
                - logs:PutLogEvents
                Effect: Allow
                Resource:
                  - !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/PipLayer-${AWS::StackName}:*
              - Action:
                - lambda:PublishLayerVersion
                - lambda:DeleteLayerVersion
                Effect: Allow
                Resource:
                  - "*"
          PolicyName: lambda

  PipLayerLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Create layers based on pip
      FunctionName: !Sub "PipLayer-${AWS::StackName}"
      Handler: index.handler
      MemorySize: 1024
      Role: !GetAtt PipLayerLambdaRole.Arn
      Runtime: python3.12
      Timeout: 300
      Code:
        ZipFile: |
          import json
          import logging
          import pathlib
          import re
          import subprocess
          import sys
          import tempfile
          import typing as t
          import shutil
          import cfnresponse
          import boto3
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          class PipLayerException(Exception):
              pass
          def _create(properties) -> t.Tuple[str, t.Mapping[str, str]]:
              try:
                  layername = properties["LayerName"]
                  description = properties.get("Description", "PipLayer")
                  packages = properties["Packages"]
              except KeyError as e:
                  raise PipLayerException("Missing parameter: %s" % e.args[0])
              description += " ({})".format(", ".join(packages))
              if not isinstance(layername, str):
                  raise PipLayerException("LayerName must be a string")
              if not isinstance(description, str):
                  raise PipLayerException("Description must be a string")
              if not isinstance(packages, list) or not all(isinstance(p, str) for p in packages):
                  raise PipLayerException("Packages must be a list of strings")
              tempdir = pathlib.Path(tempfile.TemporaryDirectory().name) / "python"
              try:
                  subprocess.check_call([
                      sys.executable, "-m", "pip", "install", *packages, "-t", tempdir])
              except subprocess.CalledProcessError:
                  raise PipLayerException("Error while installing %s" % str(packages))
              zipfilename = pathlib.Path(tempfile.NamedTemporaryFile(suffix=".zip").name)
              shutil.make_archive(
                  zipfilename.with_suffix(""), format="zip", root_dir=tempdir.parent)
              client = boto3.client("lambda")
              layer = client.publish_layer_version(
                  LayerName=layername,
                  Description=description,
                  Content={"ZipFile": zipfilename.read_bytes()},
                  CompatibleRuntimes=["python%d.%d" % sys.version_info[:2]],
              )
              logger.info("Created layer %s", layer["LayerVersionArn"])
              return (layer["LayerVersionArn"], {})
          def _delete(physical_id):
              match = re.fullmatch(
                  r"arn:aws:lambda:(?P<region>[^:]+):(?P<account>\d+):layer:"
                  r"(?P<layername>[^:]+):(?P<version_number>\d+)", physical_id)
              if not match:
                  logger.warning("Cannot parse physical id %s, not deleting", physical_id)
                  return
              layername = match.group("layername")
              version_number = int(match.group("version_number"))
              logger.info("Now deleting layer %s:%d", layername, version_number)
              client = boto3.client("lambda")
              deletion = client.delete_layer_version(
                  LayerName=layername,
                  VersionNumber=version_number)
              logger.info("Done")
          def handler(event, context):
              logger.info('{"event": %s}', json.dumps(event))
              try:
                  if event["RequestType"].upper() in ("CREATE", "UPDATE"):
                      # Note: treat UPDATE as CREATE; it will create a new physical ID,
                      # signalling CloudFormation that it's a replace and the old should be
                      # deleted
                      physicalId, attributes = _create(event["ResourceProperties"])
                      cfnresponse.send(
                          event=event,
                          context=context,
                          responseData=attributes,
                          responseStatus=cfnresponse.SUCCESS,
                          physicalResourceId=physicalId,
                      )
                  else:
                      assert event["RequestType"].upper() == "DELETE"
                      _delete(event["PhysicalResourceId"])
                      cfnresponse.send(
                          event=event,
                          context=context,
                          responseData={},
                          responseStatus=cfnresponse.SUCCESS,
                          physicalResourceId=event["PhysicalResourceId"],
                      )
              except Exception as e:
                  logger.exception("Internal Error")
                  cfnresponse.send(
                      event=event,
                      context=context,
                      responseData=None,
                      responseStatus=cfnresponse.FAILED,
                      reason=str(e))

Outputs:
  KnowledgeBaseBucket:
    Value: !Ref S3BucketName
  KnowledgeBaseId:
    Value: !Ref KnowledgeBaseWithAoss
  DataSourceId:
    Value: !GetAtt DataSource.DataSourceId